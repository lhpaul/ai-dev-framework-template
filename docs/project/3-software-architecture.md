# Software Architecture

> **STATUS: PLACEHOLDER**
>
> This document is generated by the project setup agent (`docs/ai/setup/protocol.md`).
> Run the setup workflow to populate it, or fill it in manually following the structure below.

---

## Tech Stack

> List the main technologies used, with a brief rationale for each choice.

| Layer | Technology | Notes |
|---|---|---|
| Frontend | [Framework/Library] | [Why] |
| Backend | [Framework/Runtime] | [Why] |
| Database | [DB engine] | [Why] |
| Auth | [Auth solution] | [Why] |
| Hosting | [Platform] | [Why] |
| CI/CD | [Tool] | [Why] |

## Key Architectural Decisions

> Document the major design decisions made (ADR-style, but informal). Include the context, the decision, and the consequences.

### [Decision 1: e.g., Monorepo vs. Polyrepo]

- **Context**: [Why did this come up?]
- **Decision**: [What was decided?]
- **Consequences**: [What does this enable/constrain?]

## Frontend Architecture

> Describe the frontend structure: component model, state management, routing, styling, design system.

## Backend / API Architecture

> Describe the backend structure: API style (REST/GraphQL/RPC), authentication flow, key services.

## Data Access Layer

> How does the application read/write data? Direct DB calls, ORM, generated clients, etc.

## Security Model

> Describe the security model: where authorization is enforced, how authentication works, key security principles.

## Environment Strategy

> How are environments structured (local / staging / production)? What varies per environment?

| Environment | Purpose | URL / Endpoint |
|---|---|---|
| Local | Development | localhost |
| Staging / Dev | Team testing | [URL] |
| Production | Live users | [URL] |

## External Integrations

> List third-party services integrated with the product.

| Service | Purpose | Notes |
|---|---|---|
| [Service] | [Purpose] | [Notes] |

## Testing Strategy

> **TODO**: Define the project's testing approach during setup. The recommended pattern is a two-tier model — adapt the tiers and tooling to your stack.

### Overview

| Tier | Tool | Location | When to use |
|---|---|---|---|
| **[Automated Suite]** | [e.g. Playwright, Cypress, Jest] | `[path]` | Preferred — run committed specs whenever they exist |
| **[Ad-hoc Scripts]** | [tool] | [ephemeral path] | Fallback when no spec exists yet for the feature |

The automated suite is the canonical record of what works. Ad-hoc scripts are exploratory and temporary — they are the precursor to a committed spec.

### Automated Suite

> TODO: Describe the structure, key decisions (e.g. parallelism, authentication approach, environment setup), and run commands.

```bash
# Run the full suite
[your e2e command]
```

### Relationship Between Runbooks and Specs

Each smoke test runbook (`docs/testing/[section]/[feature].smoke-test.md`) is the human-readable specification for a feature's key journeys. The corresponding automated spec is the executable implementation of that runbook.

- Runbook steps should map 1:1 to test cases in the spec.
- The runbook is the source of truth for what is tested and why; the spec is the executable implementation.
- When a new feature gets a runbook, a corresponding spec should be created or updated as part of that feature's implementation.

### Ad-hoc Scripts (Fallback)

When no spec exists for a feature yet, AI agents write a temporary automation script (e.g. at `/tmp/`). These scripts are:

- Not committed to the repository.
- Intentionally ephemeral — they validate the feature during development.
- A stepping stone: once validated, the logic should be promoted to a committed spec.

See `docs/testing/README.md` for how to decide which tier to use and how to execute each.
